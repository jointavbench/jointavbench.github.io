<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Benchmark for Joint Audio-Visual Reasoning Evaluation">
  <meta name="keywords" content="JointAVBench, Omni-LLMs, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Anonymous authors</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/docs/JointAVBench.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jointavbench/JointAVBench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/JointAVBench/JointAVBench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Benchmark</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Understanding videos inherently requires reasoning over both visual and auditory
            information. To properly evaluate Omni-Large Language Models (Omni-LLMs),
            which are capable of processing multi-modal information including vision and
            audio, an effective benchmark must comprehensively cover three key aspects: (1)
            multi-modal dependency (i.e., questions that cannot be answered using vision or
            audio alone), (2) diverse audio information types (e.g., speech, sound events), and
            (3) varying scene spans. However, existing datasets fall short in one or more of
            these dimensions, limiting strict and comprehensive evaluation. To address this gap,
            we introduce <span class="dnerf">JointAVBench</span>, a novel benchmark with strict audio-video correlation,
            spanning five cognitive dimensions, four audio information types (speech, sound
            events, music, vocal traits), and three scene spans (single-, cross-, and full-scene).
            Given the high cost of manual annotation, we propose an automated pipeline
            that leverages state-of-the-art vision-LLMs, audio-LLMs, and general-purpose
            LLMs to synthesize questions and answers that strictly require joint audio-visual
            understanding. We evaluate leading vision-only, audio-only, and Omni-LLMs
            on our dataset. Results show that even the best-performing Omni-LLM achieves
            only 56.2% average accuracy, outperforming uni-modal baselines but revealing
            substantial room for improvement, especially in cross-scene reasoning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered"> 
    <h2 class="title is-3">Data Generation</h2>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
          <figure class="content has-text-centered">
            <img src="static/images/pipeline.png">
          </figure>
      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section"> 
<div class = "container is-max-desktop">
  <div class="columns is-centered"> 
    <h2 class="title is-3">Benchmark Statistics</h2>
  </div>
  <div class="columns is-centered"> 
    <div class = "column is-four-fifths">
      <img src="static/images/statistics.png">
    </div>
  </div>

</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered"> 
    <h2 class="title is-3">Performance</h2>
    </div>
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Overall Performance</h2>
          <!-- 展示一张图片的示例代码 -->
          <figure class="content has-text-centered">
            <img src="static/images/performance.png">
          </figure>
        <!-- Interpolating. -->
        <h2 class="title is-4">Breakdown Performance</h2>
            <img src="static/images/breakdown1.png">
          <div class="columns is-centered">
            <div class="column is-7"> 
              <img src="static/images/breakdown2.png">
            </div>
          </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/docs/JointAVBench.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/jointavbench" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/jointavbench/jointavbench.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
